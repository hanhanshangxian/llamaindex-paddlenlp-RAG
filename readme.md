基于llamaindex构建的RAG应用程序
一、文件使用说明：
1、如需加载文档，请将文件放入以下存储路径：./data
2、如需查看文档索引生成的结果，可查看生成的向量数据库存储路径：./models/index
3、终端应用程序启动脚本：app.py
4、环境搭建：./models/requirements.txt
5、基于外规场景下精调后的金融大模型：checkpoint-699
6、嵌入式模型：bge-large-zh-1.5
7、app.py脚本解读：
二、脚本流程：
1、加载模型部分：请将存储路径替换为金融大模型实际存储的绝对路径
2、自定义LLM类：构建自定义LLM处理模型推理过程。LLM还配置了上下文窗口（context_window）和最大输出长度（num_output），如有修改需要可以自行修改。
3、加载嵌入模型：请将存储路径替换为嵌入式模型实际存储的绝对路径
4、构建文档摘要索引：如需用新文件加入，请重新构建文档摘要索引，取消注释该部分代码后运行程序即可
5、查询引擎（如需使用查询引擎生成回复，请直接加载脚本qa.py）
6、聊天引擎

提示:paddlenlp和paddlepaddle请从源代码进行安装
相关链接：
paddlenlp：https://github.com/PaddlePaddle/PaddleNLP
paddlepaddle：https://www.paddlepaddle.org.cn/
llamaindex:https://github.com/run-llama/llama_index